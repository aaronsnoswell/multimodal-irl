{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notebook_path = %pwd\n",
    "import sys\n",
    "sys.path.append(notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import pprint\n",
    "import gym\n",
    "import copy\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "\n",
    "from puddle_world.envs import *\n",
    "from explicit_env.soln import value_iteration, q_from_v, OptimalPolicy, policy_evaluation\n",
    "from unimodal_irl.utils import empirical_feature_expectations\n",
    "\n",
    "from multimodal_irl import bv_em_maxent, mixture_ll_maxent, responsibilty_matrix_maxent\n",
    "from multimodal_irl.metrics import *\n",
    "\n",
    "from unimodal_irl import sw_maxent_irl\n",
    "from unimodal_irl.utils import pad_terminal_mdp\n",
    "from unimodal_irl.metrics import ile_evd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environments\n",
    "env_det_wet = CanonicalPuddleWorldEnv(mode='wet', wind=0.0)\n",
    "env_det_dry = CanonicalPuddleWorldEnv(mode='dry', wind=0.0)\n",
    "env_det_any = CanonicalPuddleWorldEnv(mode='any', wind=0.0)\n",
    "_envs_det = [env_det_wet, env_det_dry, env_det_any]\n",
    "env_stoch_wet = CanonicalPuddleWorldEnv(mode='wet', wind=0.2)\n",
    "env_stoch_dry = CanonicalPuddleWorldEnv(mode='dry', wind=0.2)\n",
    "env_stoch_any = CanonicalPuddleWorldEnv(mode='any', wind=0.2)\n",
    "_envs_stoch = [env_stoch_wet, env_stoch_dry, env_stoch_any]\n",
    "\n",
    "# Load rollout data\n",
    "with open(\"pw-deterministic-wet.pkl\", \"rb\") as file:\n",
    "    rollouts_det_wet = pickle.load(file)\n",
    "with open(\"pw-deterministic-dry.pkl\", \"rb\") as file:\n",
    "    rollouts_det_dry = pickle.load(file)\n",
    "with open(\"pw-deterministic-any.pkl\", \"rb\") as file:\n",
    "    rollouts_det_any = pickle.load(file)\n",
    "with open(\"pw-stochastic-wet.pkl\", \"rb\") as file:\n",
    "    rollouts_stoch_wet = pickle.load(file)\n",
    "with open(\"pw-stochastic-dry.pkl\", \"rb\") as file:\n",
    "    rollouts_stoch_dry = pickle.load(file)\n",
    "with open(\"pw-stochastic-any.pkl\", \"rb\") as file:\n",
    "    rollouts_stoch_any = pickle.load(file)\n",
    "\n",
    "# Pre-compute optimal SD policy value for each environment\n",
    "pi_det_wet_v = policy_evaluation(\n",
    "    env_det_wet,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_det_wet), env_det_wet), stochastic=False)\n",
    ")\n",
    "pi_det_dry_v = policy_evaluation(\n",
    "    env_det_dry,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_det_dry), env_det_dry), stochastic=False)\n",
    ")\n",
    "pi_det_any_v = policy_evaluation(\n",
    "    env_det_any,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_det_any), env_det_any), stochastic=False)\n",
    ")\n",
    "_pi_vs_det = [pi_det_wet_v, pi_det_dry_v, pi_det_any_v]\n",
    "\n",
    "pi_stoch_wet_v = policy_evaluation(\n",
    "    env_stoch_wet,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_stoch_wet), env_stoch_wet), stochastic=False)\n",
    ")\n",
    "pi_stoch_dry_v = policy_evaluation(\n",
    "    env_stoch_dry,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_stoch_dry), env_stoch_dry), stochastic=False)\n",
    ")\n",
    "pi_stoch_any_v = policy_evaluation(\n",
    "    env_stoch_any,\n",
    "    OptimalPolicy(q_from_v(value_iteration(env_stoch_any), env_stoch_any), stochastic=False)\n",
    ")\n",
    "_pi_vs_stoch = [pi_stoch_wet_v, pi_stoch_dry_v, pi_stoch_any_v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "filename = \"CanonicalPuddleWorld-stochastic-2mode-experiments.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "_envs = _envs_stoch\n",
    "_env = _envs[0]\n",
    "_pi_vs = _pi_vs_stoch\n",
    "\n",
    "# Remove invalid index column\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "# Add columns for evaluation metrics\n",
    "df[\"Negative Log Likelihood\"] = np.nan\n",
    "df[\"Normalized Information Distance\"] = np.nan\n",
    "df[\"Adjusted Normalized Information Distance\"] = np.nan\n",
    "df[\"Min Cost Flow ILE\"] = np.nan\n",
    "df[\"Min Cost Flow EVD\"] = np.nan\n",
    "df[\"Mean ILE\"] = np.nan\n",
    "df[\"Mean EVD\"] = np.nan\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for _exp in tqdm(range(len(df))):\n",
    "    exp = df.iloc[_exp]\n",
    "#     print(\"Evaluating... {}/{} ({}-{} {}-{}) \".format(\n",
    "#         _exp,\n",
    "#         len(df),\n",
    "#         exp[\"Transition Type\"],\n",
    "#         int(exp[\"Num GT Clusters\"]),\n",
    "#         exp[\"Initialisation\"],\n",
    "#         int(exp[\"Num Learned Clusters\"])\n",
    "#     ), end=\"\")\n",
    "    \n",
    "    rollouts_per_mode = exp[\"Num Rollouts\"] // exp[\"Num GT Clusters\"]\n",
    "    # Get the exact set of rollouts used for this experiment\n",
    "    start_idx = int(exp[\"Replicate\"] * rollouts_per_mode)\n",
    "    end_idx = int((exp[\"Replicate\"] + 1) * rollouts_per_mode)\n",
    "    \n",
    "    if exp[\"Transition Type\"] == 'deterministic':\n",
    "        if exp[\"Num GT Clusters\"] == 2:\n",
    "            rollouts = [\n",
    "                *rollouts_det_wet[start_idx:end_idx],\n",
    "                *rollouts_det_dry[start_idx:end_idx]\n",
    "            ]\n",
    "            gt_rewards = [\n",
    "                env_det_wet.state_rewards,\n",
    "                env_det_dry.state_rewards\n",
    "            ]\n",
    "        else:\n",
    "            rollouts = [\n",
    "                *rollouts_det_wet[start_idx:end_idx],\n",
    "                *rollouts_det_dry[start_idx:end_idx],\n",
    "                *rollouts_det_any[start_idx:end_idx]\n",
    "            ]\n",
    "            gt_rewards = [\n",
    "                env_det_wet.state_rewards,\n",
    "                env_det_dry.state_rewards,\n",
    "                env_det_any.state_rewards\n",
    "            ]\n",
    "    else:\n",
    "        if exp[\"Num GT Clusters\"] == 2:\n",
    "            rollouts = [\n",
    "                *rollouts_stoch_wet[start_idx:end_idx],\n",
    "                *rollouts_stoch_dry[start_idx:end_idx]\n",
    "            ]\n",
    "            gt_rewards = [\n",
    "                env_stoch_wet.state_rewards,\n",
    "                env_stoch_dry.state_rewards\n",
    "            ]\n",
    "        else:\n",
    "            rollouts = [\n",
    "                *rollouts_stoch_wet[start_idx:end_idx],\n",
    "                *rollouts_stoch_dry[start_idx:end_idx],\n",
    "                *rollouts_stoch_any[start_idx:end_idx]\n",
    "            ]\n",
    "            gt_rewards = [\n",
    "                env_stoch_wet.state_rewards,\n",
    "                env_stoch_dry.state_rewards,\n",
    "                env_stoch_any.state_rewards\n",
    "            ]\n",
    "    \n",
    "    # Compute GT responsibility matrix\n",
    "    resp_gt = responsibilty_matrix_maxent(\n",
    "        _env,\n",
    "        rollouts,\n",
    "        int(exp[\"Num GT Clusters\"]),\n",
    "        state_reward_weights=gt_rewards\n",
    "    )\n",
    "    \n",
    "    # Get model responsibility matrix\n",
    "    resp_learned = np.array(eval(exp[\"Responsibility Matrix\"]))\n",
    "    mode_weights_learned = np.sum(resp_learned, axis=0) / resp_learned.shape[0]\n",
    "    \n",
    "    # Get model reward weights\n",
    "    learned_rewards = np.array(eval(exp[\"Reward Weights\"]))\n",
    "    \n",
    "    # Compute the log-likelihood of this model\n",
    "    df.at[_exp, \"Negative Log Likelihood\"] = -1.0 * mixture_ll_maxent(\n",
    "        _env,\n",
    "        rollouts,\n",
    "        mode_weights_learned,\n",
    "        learned_rewards\n",
    "    )\n",
    "    \n",
    "    # Compute the aNID of this model\n",
    "    df.at[_exp, \"Normalized Information Distance\"] = normalized_information_distance(resp_learned, resp_gt)\n",
    "    df.at[_exp, \"Adjusted Normalized Information Distance\"] = adjusted_normalized_information_distance(resp_learned, resp_gt)\n",
    "    \n",
    "    # Build error matrices\n",
    "    ile_mat = np.zeros((resp_learned.shape[1], resp_gt.shape[1]))\n",
    "    evd_mat = np.zeros((resp_learned.shape[1], resp_gt.shape[1]))\n",
    "    for learned_idx in range(resp_learned.shape[1]):\n",
    "        _env_learned = copy.deepcopy(_env)\n",
    "        _env_learned._state_rewards = learned_rewards[learned_idx]\n",
    "        for gt_idx in range(resp_gt.shape[1]):\n",
    "            _env_gt = _envs[gt_idx]\n",
    "            _pi_vs_gt = _pi_vs[gt_idx]\n",
    "            \n",
    "            ile_mat[learned_idx, gt_idx], evd_mat[learned_idx, gt_idx] = ile_evd(\n",
    "                _env_gt,\n",
    "                _env_learned,\n",
    "                optimal_policy_value=_pi_vs_gt\n",
    "            )\n",
    "    \n",
    "    df.at[_exp, \"Min Cost Flow ILE\"], _ = min_cost_flow_error_metric(resp_learned, resp_gt, ile_mat)\n",
    "    df.at[_exp, \"Min Cost Flow EVD\"], _ = min_cost_flow_error_metric(resp_learned, resp_gt, evd_mat)\n",
    "    \n",
    "    df.at[_exp, \"Mean ILE\"] = mean_error_metric(resp_learned, resp_gt, ile_mat)\n",
    "    df.at[_exp, \"Mean EVD\"] = mean_error_metric(resp_learned, resp_gt, evd_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename_out = filename.replace(\".csv\", \"-metrics.csv\")\n",
    "df.to_csv(filename_out, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
