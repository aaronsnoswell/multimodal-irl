{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notebook_path = %pwd\n",
    "import sys\n",
    "sys.path.append(notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import pprint\n",
    "import gym\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "\n",
    "from puddle_world.envs import *\n",
    "from explicit_env.soln import value_iteration, q_from_v, OptimalPolicy, policy_evaluation\n",
    "from unimodal_irl.utils import empirical_feature_expectations\n",
    "\n",
    "from multimodal_irl import bv_em_maxent, mixture_ll_maxent, responsibilty_matrix_maxent\n",
    "from multimodal_irl.metrics import *\n",
    "\n",
    "from unimodal_irl import sw_maxent_irl\n",
    "from unimodal_irl.utils import pad_terminal_mdp\n",
    "from unimodal_irl.metrics import ile_evd\n",
    "\n",
    "from experiments.pw_exp import (\n",
    "    TransitionType,\n",
    "    NumGTModes,\n",
    "    ExperimentConfig,\n",
    "    get_experiment_fixed_inputs,\n",
    "    get_experiment_train_inputs,\n",
    "    get_experiment_test_inputs,\n",
    "    get_experiment_outputs\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the experimental static inputs\n",
    "config = ExperimentConfig(TransitionType.DETERMINISTIC, NumGTModes.TWO)\n",
    "fixed_inputs = get_experiment_fixed_inputs(config)\n",
    "\n",
    "# Load the experimental results\n",
    "result_filename = f\"CanonicalPuddleWorld-{config.transition_type.value}-{config.num_gt_modes.value}mode-experiments.csv\"\n",
    "df = pd.read_csv(result_filename, index_col=False)\n",
    "\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "# Add columns for evaluation metrics\n",
    "df[\"Negative Log Likelihood (Test Set)\"] = np.nan\n",
    "df[\"Negative Log Likelihood (Train Set)\"] = np.nan\n",
    "df[\"Normalized Information Distance (Test Set)\"] = np.nan\n",
    "df[\"Normalized Information Distance (Train Set)\"] = np.nan\n",
    "df[\"Adjusted Normalized Information Distance (Test Set)\"] = np.nan\n",
    "df[\"Adjusted Normalized Information Distance (Train Set)\"] = np.nan\n",
    "df[\"Min Cost Flow ILE\"] = np.nan\n",
    "df[\"Min Cost Flow EVD\"] = np.nan\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vals = []\n",
    "\n",
    "for _exp in tqdm(range(len(df))):\n",
    "    exp = df.iloc[_exp]\n",
    "#     print(\"Evaluating... {}/{} ({}-{} {}-{}) \".format(\n",
    "#         _exp,\n",
    "#         len(df),\n",
    "#         exp[\"Transition Type\"],\n",
    "#         int(exp[\"Num GT Clusters\"]),\n",
    "#         exp[\"Initialisation\"],\n",
    "#         int(exp[\"Num Learned Clusters\"])\n",
    "#     ), end=\"\")\n",
    "    \n",
    "#     if exp[\"Num Rollouts\"] != 100 or exp[\"Initialisation\"] != 'gmm':\n",
    "#         continue\n",
    "\n",
    "    #print(exp)\n",
    "    \n",
    "    # Get training and test inputs\n",
    "    train_inputs = get_experiment_train_inputs(fixed_inputs, exp)\n",
    "    test_inputs = get_experiment_test_inputs(fixed_inputs, exp)\n",
    "    \n",
    "    # Get experiment outputs\n",
    "    outputs = get_experiment_outputs(fixed_inputs, exp, test_inputs)\n",
    "    \n",
    "    # Compute the log-likelihood and clustering performance of this model on training data\n",
    "    df.at[_exp, \"Negative Log Likelihood (Train Set)\"] = -1.0 * mixture_ll_maxent(\n",
    "        fixed_inputs[\"environment_noreward\"],\n",
    "        train_inputs[\"rollouts\"],\n",
    "        outputs[\"mode_weights_learned\"],\n",
    "        outputs[\"state_reward_parameters_learned\"]\n",
    "    )\n",
    "    df.at[_exp, \"Normalized Information Distance (Train Set)\"] = normalized_information_distance(\n",
    "        outputs[\"responsibility_matrix_train\"],\n",
    "        train_inputs[\"responsibility_matrix_gt\"]\n",
    "    )\n",
    "    df.at[_exp, \"Adjusted Normalized Information Distance (Train Set)\"] = adjusted_normalized_information_distance(\n",
    "        outputs[\"responsibility_matrix_train\"],\n",
    "        train_inputs[\"responsibility_matrix_gt\"]\n",
    "    )\n",
    "    \n",
    "    # Compute the log-likelihood and clustering performance of this model on testing data\n",
    "    df.at[_exp, \"Negative Log Likelihood (Test Set)\"] = -1.0 * mixture_ll_maxent(\n",
    "        fixed_inputs[\"environment_noreward\"],\n",
    "        test_inputs[\"rollouts\"],\n",
    "        outputs[\"mode_weights_learned\"],\n",
    "        outputs[\"state_reward_parameters_learned\"]\n",
    "    )\n",
    "    \n",
    "    df.at[_exp, \"Normalized Information Distance (Test Set)\"] = normalized_information_distance(\n",
    "        outputs[\"responsibility_matrix_test\"],\n",
    "        test_inputs[\"responsibility_matrix_gt\"]\n",
    "    )\n",
    "    df.at[_exp, \"Adjusted Normalized Information Distance (Test Set)\"] = adjusted_normalized_information_distance(\n",
    "        outputs[\"responsibility_matrix_test\"],\n",
    "        test_inputs[\"responsibility_matrix_gt\"]\n",
    "    )\n",
    "    \n",
    "    # Build error matrices\n",
    "    ile_mat = np.zeros((train_inputs[\"num_learned_modes\"], train_inputs[\"num_gt_modes\"]))\n",
    "    evd_mat = np.zeros_like(ile_mat)\n",
    "    for learned_mode_idx in range(train_inputs[\"num_learned_modes\"]):\n",
    "        env_learned = copy.deepcopy(fixed_inputs[\"environment_noreward\"])\n",
    "        env_learned._state_rewards = outputs[\"state_reward_parameters_learned\"][learned_mode_idx]\n",
    "        for gt_mode_idx in range(train_inputs[\"num_gt_modes\"]):\n",
    "            env_gt = fixed_inputs[\"environments\"][gt_mode_idx]\n",
    "            gt_optimal_policy_state_value_function_gt = fixed_inputs[\"mode_optimal_policy_state_value_functions\"][gt_mode_idx]\n",
    "            \n",
    "            ile_mat[learned_mode_idx, gt_mode_idx], evd_mat[learned_mode_idx, gt_mode_idx] = ile_evd(\n",
    "                env_gt,\n",
    "                env_learned,\n",
    "                optimal_policy_value=gt_optimal_policy_state_value_function_gt\n",
    "            )\n",
    "    \n",
    "    df.at[_exp, \"Min Cost Flow ILE\"], _ = min_cost_flow_error_metric(\n",
    "        outputs[\"mode_weights_learned\"],\n",
    "        train_inputs[\"mode_weights_gt\"],\n",
    "        ile_mat\n",
    "    )\n",
    "    df.at[_exp, \"Min Cost Flow EVD\"], _ = min_cost_flow_error_metric(\n",
    "        outputs[\"mode_weights_learned\"],\n",
    "        train_inputs[\"mode_weights_gt\"],\n",
    "        evd_mat\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename_out = result_filename.replace(\".csv\", \"-metrics.csv\")\n",
    "df.to_csv(filename_out, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
